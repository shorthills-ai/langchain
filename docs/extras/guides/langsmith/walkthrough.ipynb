{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4596ea-a631-416d-a2a4-3577c140493d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LangSmith Walkthrough\n",
    "\n",
    "LangChain makes it easy to prototype LLM applications and Agents. However, delivering LLM applications to production can be deceptively difficult. You will likely have to heavily customize and iterate on your prompts, chains, and other components to create a high-quality product.\n",
    "\n",
    "To aid in this process, we've launched LangSmith, a unified platform for debugging, testing, and monitoring your LLM applications.\n",
    "\n",
    "When might this come in handy? You may find it useful when you want to:\n",
    "\n",
    "- Quickly debug a new chain, agent, or set of tools\n",
    "- Visualize how components (chains, llms, retrievers, etc.) relate and are used\n",
    "- Evaluate different prompts and LLMs for a single component\n",
    "- Run a given chain several times over a dataset to ensure it consistently meets a quality bar\n",
    "- Capture usage traces and using LLMs or analytics pipelines to generate insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fbb8f-960d-4d26-9dd5-6d6acab3ee55",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**[Create a LangSmith account](https://smith.langchain.com/) and create an API key (see bottom left corner). Familiarize yourself with the platform by looking through the [docs](https://docs.smith.langchain.com/)**\n",
    "\n",
    "Note LangSmith is in closed beta; we're in the process of rolling it out to more users. However, you can fill out the form on the website for expedited access.\n",
    "\n",
    "Now, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77d064-41b4-41fb-82e6-2d16461269ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Log runs to LangSmith\n",
    "\n",
    "First, configure your environment variables to tell LangChain to log traces. This is done by setting the `LANGCHAIN_TRACING_V2` environment variable to true.\n",
    "You can tell LangChain which project to log to by setting the `LANGCHAIN_PROJECT` environment variable (if this isn't set, runs will be logged to the `default` project). This will automatically create the project for you if it doesn't exist. You must also set the `LANGCHAIN_ENDPOINT` and `LANGCHAIN_API_KEY` environment variables.\n",
    "\n",
    "For more information on other ways to set up tracing, please reference the [LangSmith documentation](https://docs.smith.langchain.com/docs/).\n",
    "\n",
    "**NOTE:** You must also set your `OPENAI_API_KEY` and `SERPAPI_API_KEY` environment variables in order to run the following tutorial.\n",
    "\n",
    "**NOTE:** You can only access an API key when you first create it. Keep it somewhere safe.\n",
    "\n",
    "**NOTE:** You can also use a context manager in python to log traces using\n",
    "```python\n",
    "from langchain.callbacks.manager import tracing_v2_enabled\n",
    "\n",
    "with tracing_v2_enabled(project_name=\"My Project\"):\n",
    "    agent.run(\"How many people live in canada as of 2023?\")\n",
    "```\n",
    "\n",
    "However, in this example, we will use environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4780363-f05a-4649-8b1a-9b449f960ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langchain langsmith --quiet\n",
    "# %pip install google-search-results pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904db9a5-f387-4a57-914c-c8af8d39e249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"\"  # Update to your API key\n",
    "\n",
    "# Used by the agent in this tutorial\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-OPENAI-API-KEY>\"\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"<YOUR-SERPAPI-API-KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7f34b-b65c-4e09-ad52-e3ace78d0221",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create the langsmith client to interact with the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510b5ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27fa11-ddce-4af0-971e-c5c37d5b92ef",
   "metadata": {},
   "source": [
    "Create a LangChain component and log runs to the platform. In this example, we will create a ReAct-style agent with access to Search and Calculator as tools. However, LangSmith works regardless of which type of LangChain component you use (LLMs, Chat Models, Tools, Retrievers, Agents are all supported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c801853-8e96-404d-984c-51ace59cbbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab51e1e-8270-452c-ba22-22b5b5951899",
   "metadata": {},
   "source": [
    "We are running the agent concurrently on multiple inputs to reduce latency. Runs get logged to LangSmith in the background so execution latency is unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19537902-b95c-4390-80a4-f6c9a937081e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"How many people live in canada as of 2023?\",\n",
    "    \"who is dua lipa's boyfriend? what is his age raised to the .43 power?\",\n",
    "    \"what is dua lipa's boyfriend age raised to the .43 power?\",\n",
    "    \"how far is it from paris to boston in miles\",\n",
    "    \"what was the total number of points scored in the 2023 super bowl? what is that number raised to the .23 power?\",\n",
    "    \"what was the total number of points scored in the 2023 super bowl raised to the .23 power?\",\n",
    "    \"how many more points were scored in the 2023 super bowl than in the 2022 super bowl?\",\n",
    "    \"what is 153 raised to .1312 power?\",\n",
    "    \"who is kendall jenner's boyfriend? what is his height (in inches) raised to .13 power?\",\n",
    "    \"what is 1213 divided by 4345?\",\n",
    "]\n",
    "\n",
    "results = agent.batch(inputs, return_exceptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0405ff30-21fe-413d-85cf-9fa3c649efec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers.langchain import wait_for_all_tracers\n",
    "\n",
    "# Logs are submitted in a background thread to avoid blocking execution.\n",
    "# For the sake of this tutorial, we want to make sure\n",
    "# they've been submitted before moving on. This is also\n",
    "# useful for serverless deployments.\n",
    "wait_for_all_tracers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9decb964-be07-4b6c-9802-9825c8be7b64",
   "metadata": {},
   "source": [
    "Assuming you've successfully set up your environment, your agent traces should show up in the `Projects` section in the [app](https://smith.langchain.com/). Congrats!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c43c311-4e09-4d57-9ef3-13afb96ff430",
   "metadata": {},
   "source": [
    "## Evaluate another agent implementation\n",
    "\n",
    "In addition to logging runs, LangSmith also allows you to test and evaluate your LLM applications.\n",
    "\n",
    "In this section, you will leverage LangSmith to create a benchmark dataset and run AI-assisted evaluators on an agent. You will do so in a few steps:\n",
    "\n",
    "1. Create a dataset from pre-existing run inputs and outputs\n",
    "2. Initialize a new agent to benchmark\n",
    "3. Configure evaluators to grade an agent's output\n",
    "4. Run the agent over the dataset and evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab1a29-b79d-4a99-b5b1-0870c2d772b1",
   "metadata": {},
   "source": [
    "### 1. Create a LangSmith dataset\n",
    "\n",
    "Below, we use the LangSmith client to create a dataset from the agent runs you just logged above. You will use these later to measure performance for a new agent. This is simply taking the inputs and outputs of the runs and saving them as examples to a dataset. A dataset is a collection of examples, which are nothing more than input-output pairs you can use as test cases to your application.\n",
    "\n",
    "**Note: this is a simple, walkthrough example. In a real-world setting, you'd ideally first validate the outputs before adding them to a benchmark dataset to be used for evaluating other agents.**\n",
    "\n",
    "For more information on datasets, including how to create them from CSVs or other files or how to create them in the platform, please refer to the [LangSmith documentation](https://docs.smith.langchain.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17580c4b-bd04-4dde-9d21-9d4edd25b00d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = f\"calculator-example-dataset-{unique_id}\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name, description=\"A calculator example dataset\"\n",
    ")\n",
    "\n",
    "runs = client.list_runs(\n",
    "    project_name=os.environ[\"LANGCHAIN_PROJECT\"],\n",
    "    execution_order=1,  # Only return the top-level runs\n",
    "    error=False,  # Only runs that succeed\n",
    ")\n",
    "for run in runs:\n",
    "    client.create_example(inputs=run.inputs, outputs=run.outputs, dataset_id=dataset.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adfd29c-b258-49e5-94b4-74597a12ba16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Initialize a new agent to benchmark\n",
    "\n",
    "You can evaluate any LLM, chain, or agent. Since chains can have memory, we will pass in a `chain_factory` (aka a `constructor` ) function to initialize for each call.\n",
    "\n",
    "In this case, we will test an agent that uses OpenAI's function calling endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42d8ecc-d46a-448b-a89c-04b0f6907f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "\n",
    "# Since chains can be stateful (e.g. they can have memory), we provide\n",
    "# a way to initialize a new chain for each row in the dataset. This is done\n",
    "# by passing in a factory function that returns a new chain for each row.\n",
    "def agent_factory():\n",
    "    return initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=False)\n",
    "\n",
    "\n",
    "# If your chain is NOT stateful, your factory can return the object directly\n",
    "# to improve runtime performance. For example:\n",
    "# chain_factory = lambda: agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9ef53",
   "metadata": {},
   "source": [
    "### 3. Configure evaluation\n",
    "\n",
    "Manually comparing the results of chains in the UI is effective, but it can be time consuming.\n",
    "It can be helpful to use automated metrics and AI-assisted feedback to evaluate your component's performance.\n",
    "\n",
    "Below, we will create some pre-implemented run evaluators that do the following:\n",
    "- Compare results against ground truth labels. (You used the debug outputs above for this)\n",
    "- Measure semantic (dis)similarity using embedding distance\n",
    "- Evaluate 'aspects' of the agent's response in a reference-free manner using custom criteria\n",
    "\n",
    "For a longer discussion of how to select an appropriate evaluator for your use case and how to create your own\n",
    "custom evaluators, please refer to the [LangSmith documentation](https://docs.smith.langchain.com/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25dc281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation import EvaluatorType\n",
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    # Evaluators can either be an evaluator type (e.g., \"qa\", \"criteria\", \"embedding_distance\", etc.) or a configuration for that evaluator\n",
    "    evaluators=[\n",
    "        # Measures whether a QA response is \"Correct\", based on a reference answer\n",
    "        # You can also select via the raw string \"qa\"\n",
    "        EvaluatorType.QA,\n",
    "        # Measure the embedding distance between the output and the reference answer\n",
    "        # Equivalent to: EvalConfig.EmbeddingDistance(embeddings=OpenAIEmbeddings())\n",
    "        EvaluatorType.EMBEDDING_DISTANCE,\n",
    "        # Grade whether the output satisfies the stated criteria. You can select a default one such as \"helpfulness\" or provide your own.\n",
    "        RunEvalConfig.LabeledCriteria(\"helpfulness\"),\n",
    "        # Both the Criteria and LabeledCriteria evaluators can be configured with a dictionary of custom criteria.\n",
    "        RunEvalConfig.Criteria(\n",
    "            {\n",
    "                \"fifth-grader-score\": \"Do you have to be smarter than a fifth grader to answer this question?\"\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    # You can add custom StringEvaluator or RunEvaluator objects here as well, which will automatically be\n",
    "    # applied to each prediction. Check out the docs for examples.\n",
    "    custom_evaluators=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07885b10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Run the agent and evaluators\n",
    "\n",
    "Use the [arun_on_dataset](https://api.python.langchain.com/en/latest/smith/langchain.smith.evaluation.runner_utils.arun_on_dataset.html#langchain.smith.evaluation.runner_utils.arun_on_dataset) (or synchronous [run_on_dataset](https://api.python.langchain.com/en/latest/smith/langchain.smith.evaluation.runner_utils.run_on_dataset.html#langchain.smith.evaluation.runner_utils.run_on_dataset)) function to evaluate your model. This will:\n",
    "1. Fetch example rows from the specified dataset\n",
    "2. Run your llm or chain on each example.\n",
    "3. Apply evalutors to the resulting run traces and corresponding reference examples to generate automated feedback.\n",
    "\n",
    "The results will be visible in the LangSmith app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3733269b-8085-4644-9d5d-baedcff13a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example f8dfff24-d288-4d8e-ba94-c3cc33dd10d0 with inputs {'input': \"what is dua lipa's boyfriend age raised to the .43 power?\"}\n",
      "Error Type: ValueError, Message: LLMMathChain._evaluate(\"\n",
      "age_of_Dua_Lipa_boyfriend ** 0.43\n",
      "\") raised error: 'age_of_Dua_Lipa_boyfriend'. Please try again with a valid numerical expression\n",
      "Chain failed for example 78c959a4-467d-4469-8bd7-c5f0b059bc4a with inputs {'input': \"who is dua lipa's boyfriend? what is his age raised to the .43 power?\"}\n",
      "Error Type: ValueError, Message: LLMMathChain._evaluate(\"\n",
      "age ** 0.43\n",
      "\") raised error: 'age'. Please try again with a valid numerical expression\n",
      "Chain failed for example 6de48a56-3f30-4aac-b6cf-eee4b05ad43f with inputs {'input': \"who is kendall jenner's boyfriend? what is his height (in inches) raised to .13 power?\"}\n",
      "Error Type: ToolException, Message: Too many arguments to single-input tool Calculator. Args: ['height ^ 0.13', {'height': 72}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.smith import (\n",
    "    arun_on_dataset,\n",
    "    run_on_dataset, \n",
    ")\n",
    "\n",
    "chain_results = run_on_dataset(\n",
    "    client=client,\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=agent_factory,\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    "    tags=[\"testing-notebook\"],  # Optional, adds a tag to the resulting chain runs\n",
    ")\n",
    "\n",
    "# Sometimes, the agent will error due to parsing issues, incompatible tool inputs, etc.\n",
    "# These are logged as warnings here and captured as errors in the tracing UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da60638-5be8-4b5f-a721-2c6627aeaf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>reference</th>\n",
       "      <th>embedding_cosine_distance</th>\n",
       "      <th>correctness</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>fifth-grader-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78c959a4-467d-4469-8bd7-c5f0b059bc4a</th>\n",
       "      <td>{'input': 'who is dua lipa's boyfriend? what i...</td>\n",
       "      <td>{'Error': 'ValueError('LLMMathChain._evaluate(...</td>\n",
       "      <td>{'output': 'Romain Gavras' age raised to the 0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8dfff24-d288-4d8e-ba94-c3cc33dd10d0</th>\n",
       "      <td>{'input': 'what is dua lipa's boyfriend age ra...</td>\n",
       "      <td>{'Error': 'ValueError('LLMMathChain._evaluate(...</td>\n",
       "      <td>{'output': 'Approximately 4.9888126515157.'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c78d5e84-3fbd-442f-affb-4b0e5806c439</th>\n",
       "      <td>{'input': 'how far is it from paris to boston ...</td>\n",
       "      <td>{'input': 'how far is it from paris to boston ...</td>\n",
       "      <td>{'output': 'The distance from Paris to Boston ...</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02cadef9-5794-49a9-8e43-acca977cab60</th>\n",
       "      <td>{'input': 'How many people live in canada as o...</td>\n",
       "      <td>{'input': 'How many people live in canada as o...</td>\n",
       "      <td>{'output': 'The current population of Canada a...</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e888a340-0486-4552-bb4b-911756e6bed7</th>\n",
       "      <td>{'input': 'what was the total number of points...</td>\n",
       "      <td>{'input': 'what was the total number of points...</td>\n",
       "      <td>{'output': '3'}</td>\n",
       "      <td>0.225076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b1f655b-754c-474d-8832-e6ec6bad3943</th>\n",
       "      <td>{'input': 'what was the total number of points...</td>\n",
       "      <td>{'input': 'what was the total number of points...</td>\n",
       "      <td>{'output': 'The total number of points scored ...</td>\n",
       "      <td>0.011580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51f1b1f1-3b51-400f-b871-65f8a3a3c2d4</th>\n",
       "      <td>{'input': 'how many more points were scored in...</td>\n",
       "      <td>{'input': 'how many more points were scored in...</td>\n",
       "      <td>{'output': '15'}</td>\n",
       "      <td>0.251002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83339364-0135-4efd-a24a-f3bd2a85e33a</th>\n",
       "      <td>{'input': 'what is 153 raised to .1312 power?'}</td>\n",
       "      <td>{'input': 'what is 153 raised to .1312 power?'...</td>\n",
       "      <td>{'output': '1.9347796717823205'}</td>\n",
       "      <td>0.127441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6de48a56-3f30-4aac-b6cf-eee4b05ad43f</th>\n",
       "      <td>{'input': 'who is kendall jenner's boyfriend? ...</td>\n",
       "      <td>{'Error': 'ToolException(\"Too many arguments t...</td>\n",
       "      <td>{'output': 'Bad Bunny's height raised to the p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0c41cc28-9c07-4550-8940-68b58cbc045e</th>\n",
       "      <td>{'input': 'what is 1213 divided by 4345?'}</td>\n",
       "      <td>{'input': 'what is 1213 divided by 4345?', 'ou...</td>\n",
       "      <td>{'output': '0.2791714614499425'}</td>\n",
       "      <td>0.144522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  input  \\\n",
       "78c959a4-467d-4469-8bd7-c5f0b059bc4a  {'input': 'who is dua lipa's boyfriend? what i...   \n",
       "f8dfff24-d288-4d8e-ba94-c3cc33dd10d0  {'input': 'what is dua lipa's boyfriend age ra...   \n",
       "c78d5e84-3fbd-442f-affb-4b0e5806c439  {'input': 'how far is it from paris to boston ...   \n",
       "02cadef9-5794-49a9-8e43-acca977cab60  {'input': 'How many people live in canada as o...   \n",
       "e888a340-0486-4552-bb4b-911756e6bed7  {'input': 'what was the total number of points...   \n",
       "1b1f655b-754c-474d-8832-e6ec6bad3943  {'input': 'what was the total number of points...   \n",
       "51f1b1f1-3b51-400f-b871-65f8a3a3c2d4  {'input': 'how many more points were scored in...   \n",
       "83339364-0135-4efd-a24a-f3bd2a85e33a    {'input': 'what is 153 raised to .1312 power?'}   \n",
       "6de48a56-3f30-4aac-b6cf-eee4b05ad43f  {'input': 'who is kendall jenner's boyfriend? ...   \n",
       "0c41cc28-9c07-4550-8940-68b58cbc045e         {'input': 'what is 1213 divided by 4345?'}   \n",
       "\n",
       "                                                                                 output  \\\n",
       "78c959a4-467d-4469-8bd7-c5f0b059bc4a  {'Error': 'ValueError('LLMMathChain._evaluate(...   \n",
       "f8dfff24-d288-4d8e-ba94-c3cc33dd10d0  {'Error': 'ValueError('LLMMathChain._evaluate(...   \n",
       "c78d5e84-3fbd-442f-affb-4b0e5806c439  {'input': 'how far is it from paris to boston ...   \n",
       "02cadef9-5794-49a9-8e43-acca977cab60  {'input': 'How many people live in canada as o...   \n",
       "e888a340-0486-4552-bb4b-911756e6bed7  {'input': 'what was the total number of points...   \n",
       "1b1f655b-754c-474d-8832-e6ec6bad3943  {'input': 'what was the total number of points...   \n",
       "51f1b1f1-3b51-400f-b871-65f8a3a3c2d4  {'input': 'how many more points were scored in...   \n",
       "83339364-0135-4efd-a24a-f3bd2a85e33a  {'input': 'what is 153 raised to .1312 power?'...   \n",
       "6de48a56-3f30-4aac-b6cf-eee4b05ad43f  {'Error': 'ToolException(\"Too many arguments t...   \n",
       "0c41cc28-9c07-4550-8940-68b58cbc045e  {'input': 'what is 1213 divided by 4345?', 'ou...   \n",
       "\n",
       "                                                                              reference  \\\n",
       "78c959a4-467d-4469-8bd7-c5f0b059bc4a  {'output': 'Romain Gavras' age raised to the 0...   \n",
       "f8dfff24-d288-4d8e-ba94-c3cc33dd10d0       {'output': 'Approximately 4.9888126515157.'}   \n",
       "c78d5e84-3fbd-442f-affb-4b0e5806c439  {'output': 'The distance from Paris to Boston ...   \n",
       "02cadef9-5794-49a9-8e43-acca977cab60  {'output': 'The current population of Canada a...   \n",
       "e888a340-0486-4552-bb4b-911756e6bed7                                    {'output': '3'}   \n",
       "1b1f655b-754c-474d-8832-e6ec6bad3943  {'output': 'The total number of points scored ...   \n",
       "51f1b1f1-3b51-400f-b871-65f8a3a3c2d4                                   {'output': '15'}   \n",
       "83339364-0135-4efd-a24a-f3bd2a85e33a                   {'output': '1.9347796717823205'}   \n",
       "6de48a56-3f30-4aac-b6cf-eee4b05ad43f  {'output': 'Bad Bunny's height raised to the p...   \n",
       "0c41cc28-9c07-4550-8940-68b58cbc045e                   {'output': '0.2791714614499425'}   \n",
       "\n",
       "                                      embedding_cosine_distance  correctness  \\\n",
       "78c959a4-467d-4469-8bd7-c5f0b059bc4a                        NaN          NaN   \n",
       "f8dfff24-d288-4d8e-ba94-c3cc33dd10d0                        NaN          NaN   \n",
       "c78d5e84-3fbd-442f-affb-4b0e5806c439                   0.007577          1.0   \n",
       "02cadef9-5794-49a9-8e43-acca977cab60                   0.016324          1.0   \n",
       "e888a340-0486-4552-bb4b-911756e6bed7                   0.225076          0.0   \n",
       "1b1f655b-754c-474d-8832-e6ec6bad3943                   0.011580          0.0   \n",
       "51f1b1f1-3b51-400f-b871-65f8a3a3c2d4                   0.251002          1.0   \n",
       "83339364-0135-4efd-a24a-f3bd2a85e33a                   0.127441          1.0   \n",
       "6de48a56-3f30-4aac-b6cf-eee4b05ad43f                        NaN          NaN   \n",
       "0c41cc28-9c07-4550-8940-68b58cbc045e                   0.144522          1.0   \n",
       "\n",
       "                                      helpfulness  fifth-grader-score  \n",
       "78c959a4-467d-4469-8bd7-c5f0b059bc4a          NaN                 NaN  \n",
       "f8dfff24-d288-4d8e-ba94-c3cc33dd10d0          NaN                 NaN  \n",
       "c78d5e84-3fbd-442f-affb-4b0e5806c439          1.0                 1.0  \n",
       "02cadef9-5794-49a9-8e43-acca977cab60          1.0                 1.0  \n",
       "e888a340-0486-4552-bb4b-911756e6bed7          0.0                 0.0  \n",
       "1b1f655b-754c-474d-8832-e6ec6bad3943          0.0                 0.0  \n",
       "51f1b1f1-3b51-400f-b871-65f8a3a3c2d4          1.0                 1.0  \n",
       "83339364-0135-4efd-a24a-f3bd2a85e33a          1.0                 1.0  \n",
       "6de48a56-3f30-4aac-b6cf-eee4b05ad43f          NaN                 NaN  \n",
       "0c41cc28-9c07-4550-8940-68b58cbc045e          1.0                 1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_results.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacd159-eb4d-49e9-bb2a-c55322c40ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Review the test results\n",
    "\n",
    "You can review the test results tracing UI below by navigating to the \"Datasets & Testing\" page and selecting the **\"calculator-example-dataset-*\"** dataset, clicking on the `Test Runs` tab, then inspecting the runs in the corresponding project. \n",
    "\n",
    "This will show the new runs and the feedback logged from the selected evaluators. Note that runs that error out will not have feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c819e-9932-45cf-adab-63727dd49559",
   "metadata": {},
   "source": [
    "## Exporting datasets and runs\n",
    "\n",
    "LangSmith lets you export data to common formats such as CSV or JSONL directly in the web app. You can also use the client to fetch runs for further analysis, to store in your own database, or to share with others. Let's fetch the run traces from the evaluation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33bfefde-d1bb-4f50-9f7a-fd572ee76820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id=UUID('a6893e95-a9cc-43e0-b9fa-f471b0cfee83'), name='AgentExecutor', start_time=datetime.datetime(2023, 9, 13, 22, 34, 32, 177406), run_type='chain', end_time=datetime.datetime(2023, 9, 13, 22, 34, 37, 77740), extra={'runtime': {'cpu': {'time': {'sys': 3.153218304, 'user': 5.045262336}, 'percent': 0.0, 'ctx_switches': {'voluntary': 42164.0, 'involuntary': 0.0}}, 'mem': {'rss': 184205312.0}, 'library': 'langchain', 'runtime': 'python', 'platform': 'macOS-13.4.1-arm64-arm-64bit', 'sdk_version': '0.0.26', 'thread_count': 58.0, 'library_version': '0.0.286', 'runtime_version': '3.11.2', 'langchain_version': '0.0.286', 'py_implementation': 'CPython'}}, error=None, serialized=None, events=[{'name': 'start', 'time': '2023-09-13T22:34:32.177406'}, {'name': 'end', 'time': '2023-09-13T22:34:37.077740'}], inputs={'input': 'what is 1213 divided by 4345?'}, outputs={'output': '1213 divided by 4345 is approximately 0.2792.'}, reference_example_id=UUID('0c41cc28-9c07-4550-8940-68b58cbc045e'), parent_run_id=None, tags=['openai-functions', 'testing-notebook'], execution_order=1, session_id=UUID('7865a050-467e-4c58-9322-58a26f182ecb'), child_run_ids=[UUID('37faef05-b6b3-4cb7-a6db-471425e69b46'), UUID('2d6a895f-de2c-4f7f-b5f1-ca876d38e530'), UUID('e7d145e3-74b0-4f32-9240-3e370becdf8f'), UUID('10db62c9-fe4f-4aba-959a-ad02cfadfa20'), UUID('8dc46a27-8ab9-4f33-9ec1-660ca73ebb4f'), UUID('eccd042e-dde0-4425-b62f-e855e25d6b64')], child_runs=None, feedback_stats={'correctness': {'n': 1, 'avg': 1.0, 'mode': 1, 'is_all_model': True}, 'helpfulness': {'n': 1, 'avg': 1.0, 'mode': 1, 'is_all_model': True}, 'fifth-grader-score': {'n': 1, 'avg': 1.0, 'mode': 1, 'is_all_model': True}, 'embedding_cosine_distance': {'n': 1, 'avg': 0.144522385071361, 'mode': 0.144522385071361, 'is_all_model': True}}, app_path='/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/7865a050-467e-4c58-9322-58a26f182ecb/r/a6893e95-a9cc-43e0-b9fa-f471b0cfee83', manifest_id=None, status='success', prompt_tokens=None, completion_tokens=None, total_tokens=None, first_token_time=None, parent_run_ids=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = list(client.list_runs(project_name=chain_results[\"project_name\"], execution_order=1))\n",
    "runs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6595c888-1f5c-4ae3-9390-0a559f5575d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TracerSessionResult(id=UUID('7865a050-467e-4c58-9322-58a26f182ecb'), start_time=datetime.datetime(2023, 9, 13, 22, 34, 10, 611846), name='test-dependable-stop-67', extra=None, tenant_id=UUID('ebbaf2eb-769b-4505-aca2-d11de10372a4'), run_count=None, latency_p50=None, latency_p99=None, total_tokens=None, prompt_tokens=None, completion_tokens=None, last_run_start_time=None, feedback_stats=None, reference_dataset_ids=None, run_facets=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After some time, these will be populated.\n",
    "client.read_project(project_name=chain_results[\"project_name\"]).feedback_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646f0fb-81d4-43ce-8a9b-54b8e19841e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have succesfully traced and evaluated an agent using LangSmith!\n",
    "\n",
    "This was a quick guide to get started, but there are many more ways to use LangSmith to speed up your developer flow and produce better results.\n",
    "\n",
    "For more information on how you can get the most out of LangSmith, check out [LangSmith documentation](https://docs.smith.langchain.com/), and please reach out with questions, feature requests, or feedback at [support@langchain.dev](mailto:support@langchain.dev)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
